{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cc6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2225c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d60f788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"lolol this quiz has got to be most ridiculous quiz I have ever done in my life.\n",
    "never had I just looked at the qn and select the first option that I see and click next.\n",
    "that's how much of a rush we were in lmaoo. I thought can crtl f in my pdf file. \n",
    "lmao i was so wrong. I don't even have time to think bruh :)\n",
    "\"\"\"\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not (token.text in string.punctuation) and token.text!= \"\\n\":\n",
    "            cleaned.append(token.lemma_.lower())\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ffff2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lolol',\n",
       " 'quiz',\n",
       " 'get',\n",
       " 'ridiculous',\n",
       " 'quiz',\n",
       " 'life',\n",
       " 'look',\n",
       " 'qn',\n",
       " 'select',\n",
       " 'option',\n",
       " 'click',\n",
       " 'rush',\n",
       " 'lmaoo',\n",
       " 'think',\n",
       " 'crtl',\n",
       " 'f',\n",
       " 'pdf',\n",
       " 'file',\n",
       " 'lmao',\n",
       " 'wrong',\n",
       " 'time',\n",
       " 'think',\n",
       " 'bruh',\n",
       " ':)']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa3e0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3,4,5]\n",
    "y = [9,8,7,6,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab323d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff042eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c766936a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Pipelining\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mspacy_tokenizer\u001b[49m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LinearSVC()\n\u001b[0;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaner\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictors()),\n\u001b[0;32m      5\u001b[0m                  (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer\u001b[39m\u001b[38;5;124m'\u001b[39m, vectorizer),\n\u001b[0;32m      6\u001b[0m                  (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, classifier)])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spacy_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Pipelining\n",
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "classifier = LinearSVC()\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f866d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea4efabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>rentals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  mnth  holiday  weekday  workingday  weathersit      temp     atemp  \\\n",
       "0       1     1        0        6           0           2  0.344167  0.363625   \n",
       "1       1     1        0        0           0           2  0.363478  0.353739   \n",
       "2       1     1        0        1           1           1  0.196364  0.189405   \n",
       "3       1     1        0        2           1           1  0.200000  0.212122   \n",
       "4       1     1        0        3           1           1  0.226957  0.229270   \n",
       "\n",
       "        hum  windspeed  rentals  \n",
       "0  0.805833   0.160446      331  \n",
       "1  0.696087   0.248539      131  \n",
       "2  0.437273   0.248309      120  \n",
       "3  0.590435   0.160296      108  \n",
       "4  0.436957   0.186900       82  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc6f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['season'\n",
    "             , 'mnth'\n",
    "             , 'holiday'\n",
    "             , 'weekday'\n",
    "             , 'workingday'\n",
    "             , 'weathersit'\n",
    "             , 'temp'\n",
    "             , 'atemp'\n",
    "             , 'hum'\n",
    "             , 'windspeed'\n",
    "             , 'rentals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5760bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train and test\n",
    "X = data.drop('rentals',axis=1)\n",
    "y = data['rentals']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0d6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='mean'))\n",
    "      ,('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "       ('imputer', SimpleImputer(strategy='constant'))\n",
    "      ,('encoder', OrdinalEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb835f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split columns into numeric/categorical\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "   ,('categorical', categorical_transformer, categorical_features)\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fee315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator pipeline\n",
    "pipeline = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('regressor',RandomForestRegressor())\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb59d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('numeric',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['temp', 'atemp', 'hum',\n",
      "                                                   'windspeed']),\n",
      "                                                 ('categorical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='constant')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OrdinalEncoder())]),\n",
      "                                                  ['season', 'mnth', 'holiday',\n",
      "                                                   'weekday', 'workingday',\n",
      "                                                   'weathersit'])])),\n",
      "                ('regressor', RandomForestRegressor())])\n"
     ]
    }
   ],
   "source": [
    "rf_model = pipeline.fit(X_train, y_train)\n",
    "print (rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f75685c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7698523765881256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions = rf_model.predict(X_test)\n",
    "print (r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b83163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#joblib.dump(rf_model, './rf_model.pkl') #save trained model in a file\n",
    "#rf_model = joblib.load('PATH/TO/rf_model.pkl') #load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e64246a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 699.76,  576.08,  584.93,  271.53, 1004.67, 1836.12,  493.79,\n",
       "        803.84,  924.04,  307.74,  596.35, 1489.11, 2507.53, 1202.76,\n",
       "        299.96,  849.09, 1359.26, 2033.9 ,  763.5 ,  661.24, 2498.91,\n",
       "       2071.7 ,   54.2 ,  915.04,  803.45,  208.06,  775.89,   62.05,\n",
       "        745.01,  561.82, 1186.87,  710.13, 1115.68, 1204.52, 1270.6 ,\n",
       "       1042.38,  847.56,  699.7 ,  845.34,  212.69,  794.83,   98.37,\n",
       "        274.37,  592.99,  471.15,  691.47,  701.66,  799.94,  240.51,\n",
       "        138.48,  511.96,  354.52,  796.24,  343.42,  760.49,  789.3 ,\n",
       "       1290.78,  797.73,  701.63, 1192.47,  972.2 ,  170.27,  635.1 ,\n",
       "       2126.87, 1402.48,  127.39,   62.69,  478.93,  285.24, 1747.95,\n",
       "        754.81,  327.66,  950.95,  820.58,  132.39,  672.65,  139.23,\n",
       "        498.8 , 1197.83,  264.6 ,  589.13,  638.24,  714.87,  786.53,\n",
       "       1437.64,  807.07,  282.95, 1165.09, 1075.14,  208.69,  813.21,\n",
       "       2194.78,  591.07,  489.21,  389.38, 2226.97,  275.66,  728.97,\n",
       "        656.66,  591.18,  517.1 , 1166.47,  342.67, 2491.61,  495.74,\n",
       "        299.26,  289.65,  443.66,   67.86,  591.2 ,  909.32, 2083.17,\n",
       "        731.82,  851.89,  195.29,  300.68,  461.7 ,  808.68,  465.65,\n",
       "        196.05,  201.56, 1031.14, 1125.74,  970.8 , 1506.38, 2347.16,\n",
       "        690.14,  736.98,  934.41, 1227.76,  843.02,  799.96, 2110.88,\n",
       "        300.1 ,  558.26,  695.62, 1551.25,  936.15, 1743.03, 1457.65,\n",
       "        231.67, 2309.72, 2223.56,  987.96,  811.19, 1133.  ,  766.82])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "933f120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488     764\n",
       "421     515\n",
       "91      898\n",
       "300     456\n",
       "177     854\n",
       "       ... \n",
       "631    2454\n",
       "548     904\n",
       "439    1005\n",
       "449    1532\n",
       "124     614\n",
       "Name: rentals, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cced7c",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf0757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Pipeline([\n",
    " ('count vectorizer',CountVectorizer(stop_words=stopwords,lowercase=True)),\n",
    " ('chi2score',SelectKBest(chi2,k=1000)),\n",
    " ('tf_transformer',TfidfVectorizer(use_idf=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44709386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class TextPreprocessor():\n",
    "#    def __init__(self, variety=\"BrE\", user_abbrevs={}, n_jobs=1):\n",
    "#        self.variety = variety\n",
    "#        self.user_abbrevs = user_abbrevs\n",
    "#        self.n_jobs = n_jobs\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, text):\n",
    "        cleaned = []\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        for message in text:\n",
    "            str = \"\"\n",
    "            doc = nlp(message)\n",
    "            for token in doc:\n",
    "                if not token.is_stop and not (token.text in string.punctuation) and token.text!= \"\\n\":\n",
    "                    str += token.lemma_.lower() + \" \"\n",
    "            cleaned.append(str[0:len(str)-1])\n",
    "        return cleaned\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66b996a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "RFR = Pipeline([\n",
    "    (\"text_preprocess\", TextPreprocessor()),\n",
    "    ('count vectorizer', CountVectorizer()),\n",
    "    ('chi2score', SelectKBest(chi2,k=50)),\n",
    "    ('tf_transformer', TfidfTransformer()),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19f3a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>is well liked cause the prof is great, and the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>It was fun but like someone else said, languag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>I can easily say that it is the most useful or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Probably the most fun mod I've taken in NUS so...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>It was really a really fun mod going through t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Comment Emotion  Rating\n",
       "145  is well liked cause the prof is great, and the...     NaN       8\n",
       "146  It was fun but like someone else said, languag...     NaN       5\n",
       "147  I can easily say that it is the most useful or...     NaN       8\n",
       "148  Probably the most fun mod I've taken in NUS so...     NaN      10\n",
       "149  It was really a really fun mod going through t...     NaN       9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Comments Review - Sheet1.csv\")[[\"Comment\",\"Emotion\",\"Rating\"]]\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0725f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RFR.fit(dataset[\"Comment\"], dataset[\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "973bcc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The email was very comprehensive but ultimately have no resolution whatsoever. Its all full of jargons that ultimately defends themselves.  They really didn't think anything is wrong with using SQL query to marks open ended qns about ethics and instead highlighted the inconsequential typo of Aggregate-Utility and Aggregate Utility.  And while they promised to mark leniently, they never say they r going to mark manually. Arguably that can means SQL 'like' or fuzzy search or whatever technology they can get their hands on.  Moreover they still defend the 'experiential' learning that IS1103 has. Things like matching graduation robe. Deducing where the fictional professor died. Why the fictional Rabbit AI is like that. Putting timestamps on a hoax video and things irrelevant to IS 1103 and they still have the gall to imply in the email that it is our fault by not getting used to the experiential learning because we r used to didactic learning.  The professor also still defend himself and says that he responds to all emails asking about mission progress even though everyone knows his response is just that ' ur activity is tracked' no percentage of completions no nothing.  I am very disappointed with the response. Expected too much from an internal review. Internal review is Internal Review after all.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.83141667])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = input(\"Enter text: \")\n",
    "model1.predict([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0a677d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = Pipeline([\n",
    "    (\"text_preprocess\", TextPreprocessor()),\n",
    "    ('count vectorizer', CountVectorizer()),\n",
    "    ('chi2score', SelectKBest(chi2,k=50)),\n",
    "    ('tf_transformer', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a93dcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NB.fit(dataset[\"Comment\"], dataset[\"Rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f83b86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The email was very comprehensive but ultimately have no resolution whatsoever. Its all full of jargons that ultimately defends themselves.  They really didn't think anything is wrong with using SQL query to marks open ended qns about ethics and instead highlighted the inconsequential typo of Aggregate-Utility and Aggregate Utility.  And while they promised to mark leniently, they never say they r going to mark manually. Arguably that can means SQL 'like' or fuzzy search or whatever technology they can get their hands on.  Moreover they still defend the 'experiential' learning that IS1103 has. Things like matching graduation robe. Deducing where the fictional professor died. Why the fictional Rabbit AI is like that. Putting timestamps on a hoax video and things irrelevant to IS 1103 and they still have the gall to imply in the email that it is our fault by not getting used to the experiential learning because we r used to didactic learning.  The professor also still defend himself and says that he responds to all emails asking about mission progress even though everyone knows his response is just that ' ur activity is tracked' no percentage of completions no nothing.  I am very disappointed with the response. Expected too much from an internal review. Internal review is Internal Review after all.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = input(\"Enter text: \")\n",
    "model2.predict([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c73069ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model1, open(\"RFR_model.sav\", 'wb'))\n",
    "pickle.dump(model2, open(\"NB_model.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2fb653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.load(open(\"RFR_model.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c2f91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.83141667])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "model.predict([\"The email was very comprehensive but ultimately have no resolution whatsoever. Its all full of jargons that ultimately defends themselves.  They really didn't think anything is wrong with using SQL query to marks open ended qns about ethics and instead highlighted the inconsequential typo of Aggregate-Utility and Aggregate Utility.  And while they promised to mark leniently, they never say they r going to mark manually. Arguably that can means SQL 'like' or fuzzy search or whatever technology they can get their hands on.  Moreover they still defend the 'experiential' learning that IS1103 has. Things like matching graduation robe. Deducing where the fictional professor died. Why the fictional Rabbit AI is like that. Putting timestamps on a hoax video and things irrelevant to IS 1103 and they still have the gall to imply in the email that it is our fault by not getting used to the experiential learning because we r used to didactic learning.  The professor also still defend himself and says that he responds to all emails asking about mission progress even though everyone knows his response is just that ' ur activity is tracked' no percentage of completions no nothing.  I am very disappointed with the response. Expected too much from an internal review. Internal review is Internal Review after all.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3b3edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424906c0efac429b9cf10aa6ccecf448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb7e619efb244b382fee55ec46ead12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5adfd3cc114478287eb595a2f938ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973ffb694e29486b8354467640cb62e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78e6a0ad7814484a75e6fde0343cce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda1638116f94b75b44a5ba9002781a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b6961579394d80adde0745117db581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'anger', 'score': 0.004419791977852583},\n",
       "  {'label': 'disgust', 'score': 0.001611992483958602},\n",
       "  {'label': 'fear', 'score': 0.0004138525982853025},\n",
       "  {'label': 'joy', 'score': 0.9771687984466553},\n",
       "  {'label': 'neutral', 'score': 0.005764591973274946},\n",
       "  {'label': 'sadness', 'score': 0.002092391485348344},\n",
       "  {'label': 'surprise', 'score': 0.008528684265911579}]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Emotion\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "classifier(\"I love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1867e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'anger', 'score': 0.7377618551254272},\n",
       "  {'label': 'disgust', 'score': 0.034230828285217285},\n",
       "  {'label': 'fear', 'score': 0.008528497070074081},\n",
       "  {'label': 'joy', 'score': 0.005797873251140118},\n",
       "  {'label': 'neutral', 'score': 0.08096954226493835},\n",
       "  {'label': 'sadness', 'score': 0.05976967513561249},\n",
       "  {'label': 'surprise', 'score': 0.07294177263975143}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "I thought it would be super difficult with many proof questions, so i practised to prove every theorem in the textbook and finished all exercise questions. Then it turned out that 70% of the paper(qn1-3) is all about computation, which is really difficult for me as i am careless and i didn't spend much time on practising calculating. So i spent most of my time working on qn1-3, which made me had insufficient time to finish qn4, but i still got qn2 and 3 wrong.\n",
    "\"\"\"\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c768f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Happy': 0.33, 'Angry': 0.0, 'Surprise': 0.33, 'Sad': 0.17, 'Fear': 0.17}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import text2emotion as te\n",
    "#import nltk\n",
    "#nltk.download('omw-1.4')\n",
    "text = \"For reference, I'm taking CS1010E with friends and if you make the effort to practice and think through your assignments, you'll do fine.\" \n",
    "te.get_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8a3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = Pipeline([\n",
    "    ('count vectorizer', CountVectorizer()),\n",
    "    ('chi2score', SelectKBest(chi2,k=1)),\n",
    "    ('tf_transformer', TfidfTransformer()),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8568912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email comprehensive ultimately resolution whatsoever',\n",
       " 'think wrong sql query mark open end qns ethic instead highlight inconsequential typo aggregate utility aggregate utility']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment1 = \"The email was very comprehensive but ultimately have no resolution whatsoever.\"\n",
    "comment2 = \"They really didn't think anything is wrong with using SQL query to marks open ended qns about ethics and instead highlighted the inconsequential typo of Aggregate-Utility and Aggregate Utility.\"\n",
    "comments = []\n",
    "comments.append(comment1)\n",
    "comments.append(comment2)\n",
    "comments\n",
    "cleaned = []\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for message in comments:\n",
    "    str = \"\"\n",
    "    doc = nlp(message)\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not (token.text in string.punctuation) and token.text!= \"\\n\":\n",
    "            str += token.lemma_.lower() + \" \"\n",
    "    cleaned.append(str[0:len(str)-1])\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffb7ce03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "k should be >=0, <= n_features = 20; got 50. Use k='all' to return all features.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m \u001b[43mRFR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    349\u001b[0m     cloned_transformer,\n\u001b[0;32m    350\u001b[0m     X,\n\u001b[0;32m    351\u001b[0m     y,\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    353\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    354\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:407\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func):\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score function should be a callable, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) was passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func))\n\u001b[0;32m    405\u001b[0m     )\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_func_ret, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:604\u001b[0m, in \u001b[0;36mSelectKBest._check_params\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m--> 604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    605\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk should be >=0, <= n_features = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m; got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse k=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to return all features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[0;32m    607\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: k should be >=0, <= n_features = 20; got 50. Use k='all' to return all features."
     ]
    }
   ],
   "source": [
    "model1 = RFR.fit(cleaned,[1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
